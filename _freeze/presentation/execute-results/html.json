{
  "hash": "14da767d10fc89f3998a958a5c95cedc",
  "result": {
    "engine": "knitr",
    "markdown": "---\n# title: \"Measurement, Causality, and <br> The Data You Don't Have </br>\"\ntitle: \"The Data You Don't Have\"\nsubtitle: \"Where is the value in data science?\"\nauthor: \"Phil Henrickson, PhD <br> Data Scientist <br> AE Business Solutions\"\nformat: \n    clean-revealjs\ncss: styles.css\neditor: source\nexecute:\n  cache: true\n  freeze: true\n---\n\n\n\n\n\n\n\n# Background\n\n## \n\n\"For a decade now, [the role of] Data Scientist has been in the spotlight. AI experts had salaries that rivaled those of sports superstars.\n\n. . .\n\nIn the search for fame and fortune, hundreds of young professionals entered into what seemed [a frenetic golden rush]{.fg style=\"--col: #C6B90B\"}... Whole new industries sprang around the hype.\n\n. . .\n\nConsulting specialists promised millions if your company could [unlock the potential of data]{.fg style=\"--col: #C6B90B\"}. \n\nAI, or Machine Learning, has been called the [new electricity]{.fg style=\"--col: #C6B90B\"} and data, the [new oil]{.fg style=\"--col: #C6B90B\"}.\"[^1]\n\n[^1]: Source: [Matheus Facure, *Causal Inference for the Brave and True*](Alveshttps://matheusfacure.github.io/python-causality-handbook/01-Introduction-To-Causality.html)\n\n##\n\n<!-- This trend has only accelerated in recent years with innovations in the form of large language models and generative artificial intelligence. -->\n\n<!-- . . . -->\n\nBut there's a problem.\n\n. . .\n\nIs all of this investment in data science actually worth anything? \n\n##  {background-image=\"images/cio_ai_roi.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##  {background-image=\"images/gs_gen_ai.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##  {background-image=\"images/ai_bubble.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##\n\nMost organizations want to advance their capabilities in DS/ML/AI. \n\n. . .\n\nAt the same, most organizations struggle to find value from them. \n\n. . .\n\nIn my humble estimation, I think this is because they are looking for value in the wrong places.\n\n##\n\n\"During all of this time...\n\n. . .\n\n-   economists were [trying to answer]{.fg style=\"--col: #75BAFF\"} what is the true impact of education on one’s earnings\n\n. . .\n\n-   biostatisticians were [trying to understand]{.fg style=\"--col: #75BAFF\"} if saturated fat led to a higher chance of a heart attack\n\n. . .\n\n-   psychologists were [trying to understand]{.fg style=\"--col: #75BAFF\"} if words of affirmation led indeed to a happier marriage.\n\n. . .\n\nWe forgot about those who have been doing “old-fashioned” science with data all along.\"[^2]\n\n[^2]: Source: [Matheus Facure, *Causal Inference for the Brave and True*](Alveshttps://matheusfacure.github.io/python-causality-handbook/01-Introduction-To-Causality.html)\n\n##\n\nWhat, really, is the value of data science?\n\n. . .\n\nThe value of data science is simply that of science - it is the process by which we [try to understand]{.fg style=\"--col: #75BAFF\"} the world around us.\n\n. . .\n\nIt allows us to discover [cause and effect]{.fg style=\"--col: #75BAFF\"}; it allows us to [measure things we care about]{.fg style=\"--col: #75BAFF\"}. It helps us understand the data we have and the data that we don’t.\n\n##\n\nTo illustrate, I want to tell you **two stories** of \"old fashioned\" data science in action.\n\n. . .\n\nThese stories involve two very different, yet related topics.\n\n. . .\n\nThe second story is about an important topic that affects us all, something that weighs on us everyday and affects the physical well-being of ourselves and our loved ones:  <span class=\"fragment\">**college football**</span>.\n\n. . .\n\nThe first story is about **heart disease**.\n\n# 1) What causes cardiovascular failure?\n\n##\n\nHave you ever gone to the doctor and received your ten-year cardiovascular risk score?\n\n. . .\n\nHave you ever wondered where that score comes from?\n\n. . .\n\nWould you have guessed that it had something to do with Franklin Delano Roosevelt?\n\n##  {background-image=\"images/fdr_before.jpg\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n\n## \n\nPresident Roosevelt died on April 12, 1945, at the age of 63, from cerebral hemorrhage with a blood pressure of **300/190 mmHg**.\n\n. . .\n\n![](images/blood_pressure.png){fig-align=\"center\"}\n\n## \n\nBy the 1940s, cardiovascular disease had become the number one cause of mortality among Americans, accounting for 1 in 2 deaths.\n\nAt this time, **almost nothing was known about the causes of heart failure**.\n\n. . .\n\nPrevention and treatment were so poorly understood that most Americans accepted **early death from heart disease as unavoidable**.\n\n## \n\nTo illustrate:\n\n. . .\n\nIn 1932, candidate Roosevelt's campaign office released medical records showing his blood pressure to be **140/100 mmHg**, which did not prompt any medical intervention.\n\n. . .\n\nBy 1941, the President experienced a gradual rise in blood pressure to **188/105 mmHg**.\n\n. . .\n\nIn March 1944, Dr. Bruenn noted that the patient appeared “slightly cyanotic” with blood pressure of **186/108 mmHg**.\n\n. . .\n\nA month after coming under Dr. Bruenn's care, Roosevelt's blood pressure had risen to **240/130 mmHg**.\n\n<!-- ##  -->\n\n<!-- In February, 1945, Lord Charles Moran, Churchill's personal physician wrote: \"the Americans here cannot bring themselves to believe that he is finished. His daughter thinks he is not really ill, and his doctor backs her up. **I give him only a few months to live**.\" -->\n\n<!-- . . . -->\n\n<!-- FDR died two months later. -->\n\n##\n\nFDR's death in April of 1945 prompted a national call for the study of cardiovascular disease.\n\n## {background-image=\"images/heart_act.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##\n\nFDR's death in April of 1945 prompted a national call for the study of cardiovascular disease.\n\nOn June 16, 1948, President Harry Truman signed into law the National Heart Act. This law approved a **twenty-year epidemiological heart study** and established the National Heart Institute.\n\n. . .\n\nThis study was the brainchild of **Joseph Mountin**, a physician from Hartford, Wisconsin.\n\n##\n\n![](images/mountin.jpg){fig-align=\"center\"}\n\n## \n\nHow do you determine the causes of long term heart risk?\n\n. . .\n\n\nJoseph Mountin recognized that the problem demanded a long term study; **collecting the necessary data**.\n\n. . .\n\n> \"Observations of population characteristics must be made **well before disease becomes overt** if the relationship of these characteristics to the development of the disease is to be established with reasonable certainty.\"\n\n##\n\nHow do you determine the causes of long term heart risk?\n\n. . .\n\n- Study a large group of people over a long period of time who have not yet developed overt symptoms of cardiovascular disease. \n\n. . .\n\n- Collect data on every individual at the start of the study and during regularly scheduled follow-ups.\n\n. . .\n\n- Observe them. Eventually, some of the individuals will experience cardiovascular disease.\n\n. . .\n\n- Examine the relationship between data collected at the beginning of the study and the onset of the disease.\n\n\n##\n\nSo that is what they decided to do.\n\n. . .\n\nThe town of **Framingham, Massachusetts** was chosen as the location for the study. \n\n##\n\n![](images/framingham_town.jpg){fig-align=\"center\"}\n\n<!-- ## -->\n<!-- ::: {layout-ncol=2} -->\n\n<!-- ![](images/framingham_aerial.jpg){width=90%} -->\n\n<!-- ![](images/framingham_town.jpg){width=60%} -->\n<!-- ::: -->\n\n<!-- . . . -->\n\n##\n\nSo that is what they decided to do.\n\nThe town of **Framingham, Massachusetts** was chosen as the location for the study. \n\nThe one-time farming community was now a factory town of 28,000 middle-class residents of predominantly European origin... and was **\"therefore considered to be representative of the United States in the 1940s\"**.\n\n::: aside\n\nThe original cohort was recruited between 1948 and 1952 and consisted of 5209 residents aged 28 to 62 years. Women comprised more than half of the participants in the study. The study's inclusion of women contrasted with contemporaneous epidemiological studies, which had very small numbers of women or excluded them altogether.\n\n:::\n\n##\n\nWhat data did they choose to collect?\n\n. . .\n\nA committee of specialists had to **speculate about the potential causes** and develop a variety of hypotheses to guide their data collection.\n\n. . .\n\nThey cast a pretty wide net in collecting data on individuals.\n\n## {background-image=\"images/data_collection.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##\n\n![](images/framingham_carbon_paper.png){fig-align=\"center\"}\n\n## \n\nWhat did they find?\n\n. . .\n\nThe first major findings were published in 1957, almost a decade after the initial participant was examined. \n\n. . .\n\nThey found a nearly 4 fold increase in coronary heart disease incidence per 1000 persons among hypertensive participants (≥160/95 mmHg).\n\n##\n\nMuch of what we know about the causes of heart disease (exercise, diet, smoking) was found in the years to come in the more than 3000 papers published using data from the Framingham Heart Study.\n\n. . .\n\nThese findings form the basis of the **Framingham Risk Score**, a simple model for estimating long term risk of cardiovascular disease that is used to this day.\n\n. . .\n\nThe Framingham study continues; it is now on its **third generation of residents**, examining the effects of family history and genetics.\n\n##\n\nWhy am I telling you about this?\n\n. . .\n\n1) The data **you choose to collect, and not collect**, is part of the scientific process.\n\n. . .\n\n2) All of the technology in the world does not matter if you do not **understand your problem** and the **data and methodology that would help you solve it**.\n\n##\n\nThe methods we use to understand something **as simple as heart disease** are the same ones we use to understand something far more serious:  <span class=\"fragment\">**college football**.</span>\n\n\n# 2) How do you measure a college football team?\n\n##\n\n![](images/uw_nw_preview.png){fig-align=\"center\"}\n\n##\n\nHave you ever looked at pre-game betting lines and win probabilities for football games?\n\n. . .\n\nHave you ever wondered how they make these predictions? It might not be quite what you think.\n\n. . .\n\nWould you have guessed that it had something to do with a quarterback who played in the 1970s?\n\n##  {background-image=\"images/virgil_carter.jpg\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##\n\n**Virgil Carter** was an NFL quarterback who played for the Bears and the Bengals in the 1970s.\n\n. . .\n\n***While also being a quarterback in the NFL***, Virgil Carter earned a Master's degree from Northwestern and taught statistics and mathematics at Xavier University.\n\n. . .\n\nThe focus of his research, naturally, was football.\n\n##  {background-image=\"images/virgil_carter_solved.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##  {background-image=\"images/operations_research_football.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n## \n\nHow do you evaluate a football team?\n\n. . .\n\nVirgil Carter's idea was to **measure the value of individual plays** in terms of **expected points**.\n\n. . .\n\nTo illustrate: how many points is each of the following plays worth?\n\n##\n\n![](gifs/eMsJcuIooJg_00-01-35_00-01-48.gif){fig-align=\"center\"}\n\n##\n\n![](gifs/eMsJcuIooJg_00-01-28_00-01-35.gif){fig-align=\"center\"}\n\n##\n\n![](gifs/G9w9Lu43UhU_00-01-23_00-01-32.gif){fig-align=\"center\"}\n\n##\n\nTo answer questions like these, Virgial Carter manually collected play-by-play data from the entire 1969 NFL season.\n\n. . .\n\nHe wanted to calculate the expected value of field position in terms of points.\n\n. . .\n\n![](images/1971_expected_points.png){fig-align=\"center\"}\n\n##\n\n![](gifs/eMsJcuIooJg_00-01-35_00-01-48.gif){fig-align=\"center\"}\n\n::: {style=\"font-size: 75%;text-align: center;\"}\nExpected Points Before Play: 1.80\\\nExpected Points After Play: 7.00\\\n**Expected Points Added: 5.20**\n:::\n\n## \n\n![](gifs/eMsJcuIooJg_00-01-28_00-01-35.gif){fig-align=\"center\"}\n\n::: {style=\"font-size: 75%;text-align: center;\"}\nExpected Points Before Play: 0.67\\\nExpected Points After Play: 1.80\\\n**Expected Points Added: 1.13**\n:::\n\n## \n\n![](gifs/G9w9Lu43UhU_00-01-23_00-01-32.gif){fig-align=\"center\"}\n\n::: {style=\"font-size: 75%;text-align: center;\"}\nExpected Points Before Play: 0.20\\\nExpected Points After Play: -3.25\\\n**Expected Points Added: -3.45**\n:::\n\n##\n\nNote: \n\nThese estimates come not from Virgil Carter's 1969 NFL Season, but my own expected points model trained on all college football plays from 2007-2019.\n\n##\n\n![](images/predicted_probability_points.png){fig-align=\"center\"}\n\n##\n\n![](images/my_expected_points.png){fig-align=\"center\"}\n\n\n## \n\nVirgil Carter's idea forms the basis of modern football analytics and how we evaluate teams and players:\n\nGood offenses generate points _in expectation_.\\\nGood defenses prevent points _in expectation_.\n\n##\n\nHow do you predict college football games?\n\n. . .\n\nYou **measure** the efficiency of **every team's offense and defense** based on every play that has occurred over the course of a season.[^3]\n\nYou then use your team measurements to simulate the outcome of games.\n\n\n[^3]: Technically, this is fairly involved and this measurement also includes plays from previous seasons with increasingly less weight assigned to them. A full discussion of this is done would take some time; I would be happy to talk about in **exhausting detail** with you later.\n\n##\n\nIs that really how they do it?\n\n. . .\n\nI was working on my own series of models for evaluating teams and eventually decided to compare my work to that of ESPN and Vegas.\n\n\n##  {background-image=\"images/espn_fpi.png\" background-position=\"center\" background-color=\"white\" background-size=\"contain\"}\n\n##\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n::: {style=\"font-size: 75%;\"}\n\nMy end of year team ratings compared to the ESPN college football power index.\n\n:::\n\n## \n\n::: {style=\"font-size: 75%;\"}\n\nMy spread vs opening spreads from providers throughout the 2024 season to date.\n\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n::: {style=\"font-size: 75%;\"}\n\nBetting lines for individual games are a little bit harder to crack; they are surely accounting for things that I (currently) am not, such as rest/injuries/travel.\n\n:::\n\n##\n\n::: {style=\"font-size: 75%;\"}\n\nPre-game simulations of Wisconsin @ USC. I felt slightly bad about nailing this one after that first half.\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n##\n\n::: {style=\"font-size: 75%;\"}\n\nBut, as with all predictive models, I don't nail every prediction. Happily, Vegas and I were both quite wrong about Wisconsin @ Rutgers last week.\n\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n<!-- ## -->\n\n<!-- Every week provides new information (plays) about teams, which is used to update a team's rating. -->\n\n<!-- ```{r} -->\n<!-- #| message: false -->\n<!-- #| warning: false -->\n<!-- #| fig-align: center -->\n<!-- plot_team_scores_by_conference = function(data, seasons = 2024, conference = 'Big Ten', lines = c(0)) { -->\n\n<!--   plot_team_lines = function(data, ylim = c(-30, 30)) { -->\n\n<!--     data |> -->\n<!--       add_season_week() |> -->\n<!--       ggplot(aes(x=week, -->\n<!--                  y=score, -->\n<!--                  color = team, -->\n<!--                  label = abbreviation))+ -->\n<!--       geom_line(stat = 'smooth', span = 0.25, method = 'loess', formula = 'y ~ x')+ -->\n<!--       cfbplotR::scale_color_cfb()+ -->\n<!--       theme_cfb()+ -->\n<!--       # coord_cartesian(ylim = ylim)+ -->\n<!--       xlab(\"Season Week\")+ -->\n<!--       ylab(\"Team Score\")+ -->\n<!--       geom_hline(yintercept = lines, linetype = 'dashed')+ -->\n<!--       coord_cartesian( -->\n<!--         #ylim = c(-33, 33), -->\n<!--         xlim = c(-1, 20) -->\n<!--       ) -->\n\n<!--   } -->\n\n<!--   label_team = function(data, var, size = 3, nudge_x = 1.2) { -->\n\n<!--     ggrepel::geom_text_repel( -->\n<!--       aes(label = {{var}}), -->\n<!--       fontface = \"bold\", -->\n<!--       size = size, -->\n<!--       direction = \"y\", -->\n<!--       nudge_x = nudge_x, -->\n<!--       segment.alpha = .5, -->\n<!--       segment.linetype = \"dotted\", -->\n<!--       box.padding = .2, -->\n<!--     segment.curvature = -0.1, -->\n<!--     segment.ncp = 3, -->\n<!--     segment.angle = 20, -->\n<!--   segment.size = 0.5 -->\n\n<!--     ) -->\n<!--   } -->\n\n<!--   data |> -->\n<!--     filter(season %in% seasons) |> -->\n<!--     join_team_info() |> -->\n<!--     inner_join( -->\n<!--       tibble( -->\n<!--         conference = conference -->\n<!--       ), by = join_by(conference) -->\n<!--     ) |> -->\n<!--     add_season_week() |> -->\n<!--     group_by(season, team) |> -->\n<!--     mutate(start_label = case_when(week == min(week) ~ abbreviation), -->\n<!--            end_label = case_when(week == max(week) ~ abbreviation)) |> -->\n<!--     plot_team_lines()+ -->\n<!--     label_team(var = end_label, size = 3, nudge_x = 1.5)+ -->\n<!--     label_team(var = start_label, size = 2, nudge_x = -0.9)+ -->\n<!--     facet_wrap(conference ~.) -->\n<!-- } -->\n\n<!-- plot_team_scores_by_conference(team_scores, conference = 'Big Ten') -->\n\n<!-- ``` -->\n\n\n<!-- ::: {style=\"font-size: 75%;\"} -->\n\n<!-- Big Ten team ratings throughout the 2024 season to date.\\ -->\n<!-- Note: ESPN and I are currently slightly at odds about Penn State and Oregon. -->\n\n<!-- ::: -->\n\n##\n\nBeyond prediction, we can monitor team performance not by outcomes but on their underlying play.\n\nAnd Wisconsin's recent performances have provided some positive news (at least on defense).\n\n##\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n##\n\nMy model still thinks Wisconsin's pass/run offense is rather mediocre, but it likes the recent performances on defense.\n\n##\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## \n\nWhy am I telling you about this?\n\n. . .\n\n1) Models are about more than just prediction; they enable us to **make sense of patterns in data** and **measure things we care about**.\n\n. . .\n\n2) The best work and the best predictions tend to come from **really trying to understand the thing you are predicting**.\n\n# \n\nwrapping up\n\n## \n\nThe value of data science is simply that of science - it is the process by which we understand the world around us.\n\n. . .\n\nIt allows us to discover [cause and effect]{.fg style=\"--col: #75BAFF\"}; it allows us to [measure things we care about]{.fg style=\"--col: #75BAFF\"}. It helps us understand the data we have and the data that we don’t.\n\n##\n\nTo recap:\n\n1) The data **you choose to collect, and not collect**, is part of the scientific process.\n\n2) All of the technology in the world does not matter if you do not **understand your problem** and the **data and methodology that would help you solve it**.\n\n3) Models are about more than just prediction; they enable us to **make sense of patterns in data** and **measure things we care about**.\n\n4) The best work and the best predictions tend to come from **really trying to understand the thing you are predicting**.\n\n#\n\none final thought\n\n##\n\nThere is no easy button; there is no tool that you can buy and start solving all of your problems.\n\n. . .\n\nThe value in (data) science usually doesn't come from algorithms, tools, platforms.\n\n. . .\n\nThe value in (data) science is usually from the [creativity/dedication/passion]{.fg style=\"--col: #75BAFF\"} of asking questions and caring about finding the answer.\n\n\n##\n\nI don't think data science is [electricity]{.fg style=\"--col: #C6B90B\"} or data the [new oil]{.fg style=\"--col: #C6B90B\"}. I think it's something much simpler.\n\n. . .\n\n(Data) science is like [farming]{.fg style=\"--col: #75BAFF\"}. \n\n. . .\n\nIt’s slow and difficult and takes a lot of patience.\n\n. . .\n\nBut if you work at it and make an effort everyday, you will produce something valuable in the end.\n\n#\n\nthanks for listening\n\n#\n\nreferences\n\n##\n\n1) Mahmood, Syed S., et al. [\"The Framingham Heart Study and the epidemiology of cardiovascular disease: a historical perspective.\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC4159698/) The lancet 383.9921 (2014): 999-1008.\n\n2) Dawber, Thomas R., Gilcin F. Meadors, and Felix E. Moore Jr. [\"Epidemiological approaches to heart disease: the Framingham Study.\"](https://ajph.aphapublications.org/doi/pdf/10.2105/AJPH.41.3.279) American Journal of Public Health and the Nations Health 41.3 (1951): 279-286.\n\n3) [Epidemiological Background and Design:\nThe Framingham Heart Study](https://www.framinghamheartstudy.org/fhs-about/history/epidemiological-background/)\n\n4) Carter, Virgil, and Robert E. Machol. [\"Operations research on football.\"](https://pubsonline.informs.org/doi/epdf/10.1287/opre.19.2.541) Operations Research 19.2 (1971): 541-544.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}