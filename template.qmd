---
# title: "Measurement, Causality, and <br> The Data You Don't Have </br>"
title: "The Data You Don't Have"
subtitle: "Where is the value in data science?"
author: "Phil Henrickson, PhD <br> Data Scientist <br> AE Business Solutions"
format: 
    clean-revealjs
css: styles.css
editor: source
execute: 
  cache: true
---


```{r}
#| include: false
# packages
library(targets)
library(dplyr)
library(tidyr)
library(ggplot2)
library(quarto)
library(gt)
library(gtExtras)
library(yardstick)
library(patchwork)
library(purrr)

# src code
tar_source("R")

```

```{r}
#| include: false
# data from targets
team_info <- tar_read("cfbd_team_info_tbl")
team_estimates <- tar_read("season_team_estimates")
team_scores <- tar_read("team_scores")
draws <- tar_read("games_draws")
sims <- tar_read("games_sims")

# team info
team_info <- cfbfastR::cfbd_team_info(year = 2024)

# estimates
team_scores = tar_read("team_scores")
team_category_estimates = tar_read("season_team_category_estimates")

draws = tar_read("games_draws")
sims = tar_read("games_sims")
games = tar_read("season_game_info")

# team info
team_info = cfbfastR::cfbd_team_info(only_fbs = T) |> as_tibble()

# espn fpi
espn_fpi = 
  map(c(2011:2023),
      ~ cfbfastR::espn_ratings_fpi(year = .x)
  ) |>
  list_rbind()

# get betting lines
betting_lines <-
  cfbfastR::cfbd_betting_lines(year = 2024) |>
  as_tibble()

# join sims with betting lines
sims_and_betting_lines = 
  sims |>
  join_betting_lines(betting = betting_lines)
```


# Background

## 

"For a decade now, [the role of] Data Scientist has been in the spotlight. AI experts had salaries that rivaled those of sports superstars.

. . .

In the search for fame and fortune, hundreds of young professionals entered into what seemed [a frenetic golden rush]{.fg style="--col: #C6B90B"}... Whole new industries sprang around the hype.

. . .

Consulting specialists promised millions if your company could [unlock the potential of data]{.fg style="--col: #C6B90B"}.  AI, or Machine Learning, has been called the [new electricity]{.fg style="--col: #C6B90B"} and data, the [new oil]{.fg style="--col: #C6B90B"}."[^1]

[^1]: Source: [Matheus Facure, *Causal Inference for the Brave and True*](Alveshttps://matheusfacure.github.io/python-causality-handbook/01-Introduction-To-Causality.html)

##

<!-- This trend has only accelerated in recent years with innovations in the form of large language models and generative artificial intelligence. -->

<!-- . . . -->

But there's a problem.

. . .

Is all of this investment in data science actually worth anything? 

##  {background-image="images/cio_ai_roi.png" background-position="center" background-color="white" background-size="contain"}

##  {background-image="images/gs_gen_ai.png" background-position="center" background-color="white" background-size="contain"}

##  {background-image="images/ai_bubble.png" background-position="center" background-color="white" background-size="contain"}

##

Most organizations want to advance their capabilities in DS/ML/AI. 

. . .

At the same, most organizations struggle to find value from them. 

. . .

In my humble estimation, I think this is because they are looking for value in the wrong places.

##

"During all of this time...

. . .

-   economists were [trying to answer]{.fg style="--col: #75BAFF"} what is the true impact of education on one’s earnings

. . .

-   biostatisticians were [trying to understand]{.fg style="--col: #75BAFF"} if saturated fat led to a higher chance of a heart attack

. . .

-   psychologists were [trying to understand]{.fg style="--col: #75BAFF"} if words of affirmation led indeed to a happier marriage.

. . .

We forgot about those who have been doing “old-fashioned” science with data all along."[^2]

[^2]: Source: [Matheus Facure, *Causal Inference for the Brave and True*](Alveshttps://matheusfacure.github.io/python-causality-handbook/01-Introduction-To-Causality.html)

##

What, really, is the value of data science?

. . .

The value of data science is simply that of science - it is the process by which we [try to understand]{.fg style="--col: #75BAFF"} the world around us.

. . .

It allows us to discover [cause and effect]{.fg style="--col: #75BAFF"}; it allows us to [measure things we care about]{.fg style="--col: #75BAFF"}. It helps us understand the data we have and the data that we don’t.

##

To illustrate, I want to tell you **two stories** of "old fashioned" data science in action.

. . .

These stories involve two very different, yet related topics.

. . .

The second story is about an important topic that affects us all, something that weighs on us everyday and affects the physical well-being of ourselves and our loved ones:  <span class="fragment">**college football**</span>.

. . .

The first story is about **heart disease**.

# 1) What causes cardiovascular failure?

##

Have you ever gone to the doctor and received your ten-year cardiovascular risk score?

. . .

Have you ever wondered where that score comes from?

. . .

Would you have guessed that it had something to do with Franklin Delano Roosevelt?

##  {background-image="images/fdr_before.jpg" background-position="center" background-color="white" background-size="contain"}


## 

President Roosevelt died on April 12, 1945, at the age of 63, from cerebral hemorrhage with a blood pressure of **300/190 mmHg**.

. . .

![](images/blood_pressure.png){fig-align="center"}

## 

By the 1940s, cardiovascular disease had become the number one cause of mortality among Americans, accounting for 1 in 2 deaths.

At this time, **almost nothing was known about the causes of heart failure**.

. . .

Prevention and treatment were so poorly understood that most Americans accepted **early death from heart disease as unavoidable**.

## 

To illustrate:

. . .

In 1932, candidate Roosevelt's campaign office released medical records showing his blood pressure to be **140/100 mmHg**, which did not prompt any medical intervention.

. . .

By 1941, the President experienced a gradual rise in blood pressure to **188/105 mmHg**.

. . .

In March 1944, Dr. Bruenn noted that the patient appeared “slightly cyanotic” with blood pressure of **186/108 mmHg**.

. . .

A month after coming under Dr. Bruenn's care, Roosevelt's blood pressure had risen to **240/130 mmHg**.

<!-- ##  -->

<!-- In February, 1945, Lord Charles Moran, Churchill's personal physician wrote: "the Americans here cannot bring themselves to believe that he is finished. His daughter thinks he is not really ill, and his doctor backs her up. **I give him only a few months to live**." -->

<!-- . . . -->

<!-- FDR died two months later. -->

##

FDR's death in April of 1945 prompted a national call for the study of cardiovascular disease.

## {background-image="images/heart_act.png" background-position="center" background-color="white" background-size="contain"}

##

On June 16, 1948, President Harry Truman signed into law the National Heart Act.

This law approved a **twenty-year epidemiological heart study** and established the National Heart Institute.

. . .

This study was the brainchild of **Joseph Mountin**, a physician from Hartford, Wisconsin.

##

![](images/mountin.jpg){fig-align="center"}

## 

How do you determine the causes of long term heart risk?

. . .


Joseph Mountin recognized that the problem demanded a long term study; **collecting the necessary data**.

. . .

"Observations of population characteristics must be made **well before disease becomes overt** if the relationship of these characteristics to the development of the disease is to be established with reasonable certainty."

##

Mountin's recommendation:

. . .

- Study a large group of people over a long period of time who had not yet developed overt symptoms of cardiovascular disease. 

. . .

- Collect data on every individual at the start of the study and during regularly scheduled follow-ups.

. . .

- Observe them. Eventually, some of the individuals would experience cardiovascular disease.

. . .

- Examine the relationship between data collected at the beginning of the study and the onset of the disease.


##

So that is what they decided to do.

. . .

The town of **Framingham, Massachusetts** was chosen as the location for the study. 

##

![](images/framingham_town.jpg){fig-align="center"}

<!-- ## -->
<!-- ::: {layout-ncol=2} -->

<!-- ![](images/framingham_aerial.jpg){width=90%} -->

<!-- ![](images/framingham_town.jpg){width=60%} -->
<!-- ::: -->

<!-- . . . -->

##

The town of **Framingham, Massachusetts** was chosen as the location for the study. 

The one-time farming community was now a factory town of 28,000 middle-class residents of predominantly European origin... and was **"therefore considered to be representative of the United States in the 1940s"**.

::: aside

The original cohort was recruited between 1948 and 1952 and consisted of 5209 residents aged 28 to 62 years. Women comprised more than half of the participants in the study. The study's inclusion of women contrasted with contemporaneous epidemiological studies, which had very small numbers of women or excluded them altogether.

:::

##

What data did they choose to collect?

. . .

A committee of specialists had to **speculate about the potential causes** and develop a variety of hypotheses to guide their data collection.

. . .

They cast a pretty wide net in collecting data on individuals.

## {background-image="images/data_collection.png" background-position="center" background-color="white" background-size="contain"}

##

![](images/framingham_carbon_paper.png){fig-align="center"}

## 

What did they find?

. . .

The first major findings were published in 1957, almost a decade after the initial participant was examined. 

. . .

They found a nearly 4 fold increase in coronary heart disease incidence per 1000 persons among hypertensive participants (≥160/95 mmHg).

##

Much of what we know about the causes of heart disease (exercise, diet, smoking) was found in the years to come in the more than 3000 papers published using data from the Framingham Heart Study.

. . .

These findings form the basis of the **Framingham Risk Score**, a simple model for estimating long term risk of cardiovascular disease that is used to this day.

. . .

The Framingham study continues; it is now on its **third generation of residents**, examining the effects of family history and genetics.

##

Why am I telling you about this?

. . .

1) The data **you choose to collect, and not collect**, is part of the scientific process.

. . .

2) All of the technology in the world does not matter if you do not **understand your problem** and the **data and methodology that would help you solve it**.

##

The methods we use to understand something **as simple as heart disease** are the same ones we use to understand something far more serious:  <span class="fragment">**college football**.</span>


# 2) How do you measure a college football team?

##

![](images/uw_nw_preview.png){fig-align="center"}

##

Have you ever looked at pre-game betting lines and win probabilities for football games?

. . .

Have you ever wondered how they make these predictions? It might not be quite what you think.

. . .

Would you have guessed that it had something to do with a quarterback who played in the 1970s?

##  {background-image="images/virgil_carter.jpg" background-position="center" background-color="white" background-size="contain"}

##

**Virgil Carter** was an NFL quarterback who played for the Bears and the Bengals in the 1970s.

. . .

***While also being a quarterback in the NFL***, Virgil Carter earned a Master's degree from Northwestern and taught statistics and mathematics at Xavier University.

. . .

The focus of his research, naturally, was football.

##  {background-image="images/virgil_carter_solved.png" background-position="center" background-color="white" background-size="contain"}

##  {background-image="images/operations_research_football.png" background-position="center" background-color="white" background-size="contain"}

## 

How do you evaluate a football team?

. . .

Virgil Carter's idea was to **measure the value of individual plays** in terms of **expected points**.

. . .

To illustrate: how many points is each of the following plays worth?

##  {background-image="gifs/eMsJcuIooJg_00-01-35_00-01-48.gif" background-position="center" background-color="white" background-size="contain"}

##  {background-image="gifs/eMsJcuIooJg_00-01-28_00-01-35.gif" background-position="center" background-color="white" background-size="contain"}

##  {background-image="gifs/G9w9Lu43UhU_00-01-23_00-01-32.gif" background-position="center" background-color="white" background-size="contain"}

##

To answer questions like these, Virgial Carter manually collected play-by-play data from the entire 1969 NFL season.

. . .

He wanted to calculate the expected value of field position in terms of points.

. . .

![](images/1971_expected_points.png){fig-align="center"}

##

![](gifs/eMsJcuIooJg_00-01-35_00-01-48.gif){fig-align="center"}

::: {style="font-size: 75%;text-align: center;"}
Expected Points Before Play: 1.80\
Expected Points After Play: 7.00\
**Expected Points Added: 5.20**
:::

## 

![](gifs/eMsJcuIooJg_00-01-28_00-01-35.gif){fig-align="center"}

::: {style="font-size: 75%;text-align: center;"}
Expected Points Before Play: 0.67\
Expected Points After Play: 1.80\
**Expected Points Added: 1.13**
:::

## 

![](gifs/G9w9Lu43UhU_00-01-23_00-01-32.gif){fig-align="center"}

::: {style="font-size: 75%;text-align: center;"}
Expected Points Before Play: 0.20\
Expected Points After Play: -3.25\
**Expected Points Added: -3.45**
:::

##

Note: these estimates come not from Virgil Carter's 1969 NFL Season, but my own expected points model trained on all college football plays from 2007-2019.

##

![](images/predicted_probability_points.png){fig-align="center"}

##

![](images/my_expected_points.png){fig-align="center"}


## 

Virgil Carter's idea forms the basis of modern football analytics and how we evaluate teams and players:

Good offenses generate points _in expectation_.\
Good defenses prevent points _in expectation_.

##

How do you predict college football games?

. . .

You **measure** the efficiency of **every team's offense and defense** based on every play that has occurred over the course of a season.[^3]

You then use your team measurements to simulate the outcome of games.


[^3]: Technically, this is fairly involved and this measurement also includes plays from previous seasons with increasingly less weight assigned to them. A full discussion of this is done would take some time; I would be happy to talk about in **exhausting detail** with you later.

##

Is that really how they do it?

. . .

I was working on my own series of models for evaluating teams and eventually decided to compare my work to that of ESPN and Vegas.


##  {background-image="images/espn_fpi.png" background-position="center" background-color="white" background-size="contain"}

##

```{r}
#| message: false
#| warning: false
#| fig-height: 6
#| fig-align: center
plot_vs_fpi = function(data) {
  
  b = 
    data |>
    ggplot(aes(x=score, y=fpi))+
    facet_wrap(season ~., ncol = 4)+
    theme_cfb()+
    geom_abline(slope = 1, 
                linetype = 'dashed')+
    #   tune::coord_obs_pred()+
    xlab("Phil's Team Rating")+
    ylab("ESPN Team Rating")+
    coord_cartesian(xlim = c(-45, 45),
                    ylim = c(-45, 45))
  
  b
}

vs_fpi = 
  team_scores |>
  find_team_season_score()  |>
  select(season, team, score) |>
  inner_join(
    team_info |>
      adjust_team_names(cols = "school") |>
      select(team = school, team_id)
  ) |>
  inner_join(
    espn_fpi |>
      select(season = year, team_id, team_abbreviation, fpi) |>
      mutate(fpi = as.numeric(fpi))
  ) 

p = 
  vs_fpi |>
  plot_vs_fpi()

p +
  geom_point(alpha = 0.25)+
  ggpubr::stat_cor(method = 'spearman', aes(label = ..r.label..))


```
::: {style="font-size: 75%;"}

My end of year team ratings compared to the ESPN college football power index.

:::

## 

::: {style="font-size: 75%;"}

My spread vs Vegas opening spread throughout the 2024 season to date.

Betting lines for individual games are a little bit harder to crack; they are surely accounting for things that I (currently) am not, such as rest/injuries/travel.

:::

```{r}
#| message: false
#| warning: false
sims_and_betting_lines |>
  filter(!is.na(provider)) |>
  ggplot(aes(x=pred_margin, y= -1*spread_open))+
  geom_point(alpha = 0.5)+
  theme_cfb()+
  tune::coord_obs_pred()+
  geom_abline(slope = 1, linetype = 'dashed')+
  ggpubr::stat_cor(aes(label = ..r.label..)) +
  facet_wrap(paste(season) ~.)+
  xlab("Phil's Estimated Spread")+
  ylab("ESPN Bet Spread")+
  coord_cartesian(xlim = c(-30, 60),
                  ylim = c(-30, 60))+
  facet_wrap(provider ~., ncol = 2)

```

##

::: {style="font-size: 75%;"}

Pre-game simulations of Wisconsin @ USC. I felt slightly bad about nailing this one after that first half.

:::


```{r}
#| message: false
#| warning: false
draws |>
  ungroup() |>
  filter(home_team == 'USC' & away_team == 'Wisconsin') |>
  inner_join(
    games |>
      add_game_outcomes() |>
      select(game_id, home_margin),
    by = join_by(game_id)
  ) |>
  plot_game_sims()+
  facet_wrap(paste(start_date, game_label, sep = "\n") ~ .)+
  geom_vline(aes(xintercept = home_margin), linetype = 'dashed')+
  theme_cfb()+
  xlab("Home Team Margin of Victory")+
  ylab("Simulations")

```


##

::: {style="font-size: 75%;"}

But, as with all predictive models, I don't nail every prediction. Happily, Vegas and I were both quite wrong about Wisconsin @ Rutgers last week.

:::

```{r}
#| message: false
#| warning: false
draws |>
  ungroup() |>
  filter(home_team == 'Wisconsin' | away_team == 'Wisconsin') |>
  inner_join(
    games |>
      add_game_outcomes() |>
      select(game_id, home_margin),
    by = join_by(game_id)
  ) |>
  plot_game_sims()+
  facet_wrap(paste(start_date, game_label, sep = "\n") ~ .)+
  geom_vline(aes(xintercept = home_margin), linetype = 'dashed')+
  theme_cfb()+
  xlab("Home Team Margin of Victory")+
  ylab("Simulations")

```


<!-- ## -->

<!-- Every week provides new information (plays) about teams, which is used to update a team's rating. -->

<!-- ```{r} -->
<!-- #| message: false -->
<!-- #| warning: false -->
<!-- #| fig-align: center -->
<!-- plot_team_scores_by_conference = function(data, seasons = 2024, conference = 'Big Ten', lines = c(0)) { -->

<!--   plot_team_lines = function(data, ylim = c(-30, 30)) { -->

<!--     data |> -->
<!--       add_season_week() |> -->
<!--       ggplot(aes(x=week, -->
<!--                  y=score, -->
<!--                  color = team, -->
<!--                  label = abbreviation))+ -->
<!--       geom_line(stat = 'smooth', span = 0.25, method = 'loess', formula = 'y ~ x')+ -->
<!--       cfbplotR::scale_color_cfb()+ -->
<!--       theme_cfb()+ -->
<!--       # coord_cartesian(ylim = ylim)+ -->
<!--       xlab("Season Week")+ -->
<!--       ylab("Team Score")+ -->
<!--       geom_hline(yintercept = lines, linetype = 'dashed')+ -->
<!--       coord_cartesian( -->
<!--         #ylim = c(-33, 33), -->
<!--         xlim = c(-1, 20) -->
<!--       ) -->

<!--   } -->

<!--   label_team = function(data, var, size = 3, nudge_x = 1.2) { -->

<!--     ggrepel::geom_text_repel( -->
<!--       aes(label = {{var}}), -->
<!--       fontface = "bold", -->
<!--       size = size, -->
<!--       direction = "y", -->
<!--       nudge_x = nudge_x, -->
<!--       segment.alpha = .5, -->
<!--       segment.linetype = "dotted", -->
<!--       box.padding = .2, -->
<!--     segment.curvature = -0.1, -->
<!--     segment.ncp = 3, -->
<!--     segment.angle = 20, -->
<!--   segment.size = 0.5 -->

<!--     ) -->
<!--   } -->

<!--   data |> -->
<!--     filter(season %in% seasons) |> -->
<!--     join_team_info() |> -->
<!--     inner_join( -->
<!--       tibble( -->
<!--         conference = conference -->
<!--       ), by = join_by(conference) -->
<!--     ) |> -->
<!--     add_season_week() |> -->
<!--     group_by(season, team) |> -->
<!--     mutate(start_label = case_when(week == min(week) ~ abbreviation), -->
<!--            end_label = case_when(week == max(week) ~ abbreviation)) |> -->
<!--     plot_team_lines()+ -->
<!--     label_team(var = end_label, size = 3, nudge_x = 1.5)+ -->
<!--     label_team(var = start_label, size = 2, nudge_x = -0.9)+ -->
<!--     facet_wrap(conference ~.) -->
<!-- } -->

<!-- plot_team_scores_by_conference(team_scores, conference = 'Big Ten') -->

<!-- ``` -->


<!-- ::: {style="font-size: 75%;"} -->

<!-- Big Ten team ratings throughout the 2024 season to date.\ -->
<!-- Note: ESPN and I are currently slightly at odds about Penn State and Oregon. -->

<!-- ::: -->

##

Beyond prediction, we can monitor team performance not by outcomes but on their underlying play.

And Wisconsin's recent performances have provided some positive news (at least on defense).

##

```{r}
#| warning: false
#| message: false
#| fig-height: 6.5
#| fig-align: center
team_scores |>
  filter(season >= 2018) |>
  plot_team_scores(team = 'Wisconsin', rankings = 25)+
  xlab("Season Week")+
  scale_x_discrete(breaks = function(x){x[c(TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE)]})

```

##

My model still thinks Wisconsin's pass/run offense is rather mediocre, but it likes the recent performances on defense.

##

```{r}
#| warning: false
#| message: false
#| fig-height: 6.5
#| fig-align: center
team_category_estimates |>
  filter(season >= 2018) |>
  plot_team_efficiency_by_category_and_week(team = "Wisconsin") +
  scale_x_discrete(breaks = function(x){x[c(TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE)]})

```


## 

Why am I telling you about this?

. . .

1) Models are about more than just prediction; they enable us to **make sense of patterns in data** and **measure things we care about**.

. . .

2) The best work and the best predictions tend to come not from supercomputers, but from **really trying to understand the thing you are predicting**.

# 

wrapping up

## 

The value of data science is simply that of science - it is the process by which we understand the world around us.

. . .

It allows us to discover [cause and effect]{.fg style="--col: #75BAFF"}; it allows us to [measure things we care about]{.fg style="--col: #75BAFF"}. It helps us understand the data we have and the data that we don’t.

##

There is no easy button; there is no tool that you can buy and start solving all of your problems.

. . .

The value in (data) science usually doesn't come from algorithms, tools, platforms.

. . .

The value in (data) science is usually from the creativity/dedication/passion of asking questions and caring about the answer.


##

I don't think data science is [electricity]{.fg style="--col: #C6B90B"} or data the [new oil]{.fg style="--col: #C6B90B"}. I think it's something much simpler.

. . .

(Data) science is like [farming]{.fg style="--col: #75BAFF"}. 

. . .

It’s slow and difficult and takes a lot of patience.

. . .

But if you work at it and make an effort everyday, you will produce something valuable in the end.

#

thanks for listening
